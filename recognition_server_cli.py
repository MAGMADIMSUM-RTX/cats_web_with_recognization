#!/usr/bin/env python3
"""
å…¨è‡ªåŠ¨AIçŒ«å’ªè¯†åˆ«æœåŠ¡å™¨
è¿è¡Œåœ¨ç«¯å£ 2255ï¼Œæ¥æ”¶å›¾ç‰‡æ–‡ä»¶ï¼Œä½¿ç”¨AIæ¨¡å‹è¿›è¡Œè¯†åˆ«å’ŒåŒ¹é…ã€‚
"""

import os
import uuid
import logging
import threading
import queue
import time
import sys

from flask import Flask, request, jsonify
from werkzeug.utils import secure_filename

# --- å¼•å…¥æˆ‘ä»¬ä¹‹å‰ç¼–å†™çš„AIè¯†åˆ«æ ¸å¿ƒä»£ç  ---
import cv2
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from ultralytics import YOLO
import numpy as np
import sqlite3
import pickle
from scipy.spatial.distance import cosine

# --- 1. é…ç½®åŒºåŸŸ ---

# æœåŠ¡å™¨é…ç½®
UPLOAD_FOLDER = 'temp_recognition'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'webp'}
SERVER_PORT = 2255

# AIæ¨¡å‹ä¸æ•°æ®åº“é…ç½®
DATABASE_FILE = '../cats_recognition.db'
YOLO_MODEL_PATH = '../models/best.pt'
SIMILARITY_THRESHOLD = 0.80  # å…³é”®é˜ˆå€¼ï¼šé«˜äºæ­¤å€¼æ‰ç¡®è®¤ä¸ºå·²çŸ¥çŒ«å’ª

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


# --- 2. AIæ¨¡å‹åŠ è½½ä¸æ ¸å¿ƒåŠŸèƒ½ ---
# (è¿™éƒ¨åˆ†ä»£ç ç›´æ¥ä» recognize_cat.py ç§»æ¤è¿‡æ¥)

def load_ai_models():
    """ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰AIæ¨¡å‹åˆ°å†…å­˜ä¸­ã€‚"""
    print("ğŸ¤– æ­£åœ¨åŠ è½½ AI æ¨¡å‹åˆ°å†…å­˜...")
    try:
        yolo = YOLO(YOLO_MODEL_PATH)
        print("   - YOLOv8 æ¨¡å‹åŠ è½½æˆåŠŸã€‚")
    except Exception as e:
        print(f"   - é”™è¯¯: æ— æ³•åŠ è½½YOLOv8æ¨¡å‹ at {YOLO_MODEL_PATH}. Error: {e}")
        return None, None

    extractor = models.mobilenet_v2(weights=models.MobileNet_V2_Weights.DEFAULT)
    extractor.classifier[1] = torch.nn.Identity()
    extractor.eval()
    print("   - MobileNetV2 ç‰¹å¾æå–å™¨åŠ è½½æˆåŠŸã€‚")

    return yolo, extractor


preprocess_transform = transforms.Compose([
    transforms.ToPILImage(), transforms.Resize((224, 224)), transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])


def extract_feature_from_image(image_path, yolo_model, feature_extractor):
    """ä»å›¾ç‰‡ä¸­æå–ç‰¹å¾å‘é‡ã€‚"""
    img = cv2.imread(image_path)
    if img is None: return None
    results = yolo_model.predict(source=img, verbose=False, conf=0.5)
    best_box = None;
    max_conf = 0
    if results[0].boxes:
        for box in results[0].boxes:
            if box.conf > max_conf: max_conf = box.conf; best_box = box.xyxy[0].cpu().numpy().astype(int)
    if best_box is not None:
        x1, y1, x2, y2 = best_box
        cropped_face = img[y1:y2, x1:x2]
        if cropped_face.size == 0: return None
        rgb_image = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)
        input_tensor = preprocess_transform(rgb_image)
        input_batch = input_tensor.unsqueeze(0)
        with torch.no_grad():
            feature_vector = feature_extractor(input_batch)
        return feature_vector.squeeze().cpu().numpy()
    return None


def deserialize_data(data_blob):
    return pickle.loads(data_blob)


def find_most_similar_cat(query_vector, db_path):
    """åœ¨æ•°æ®åº“ä¸­æœç´¢æœ€ç›¸ä¼¼çš„çŒ«ã€‚"""
    try:
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT name, feature_vectors FROM cats")
        all_cats = cursor.fetchall()
        conn.close()
    except sqlite3.Error as e:
        return None, -1.0, f"æ•°æ®åº“é”™è¯¯: {e}"
    if not all_cats: return None, -1.0, "æ•°æ®åº“ä¸ºç©º"
    best_match_name = None;
    highest_similarity = -1.0
    for name, vectors_blob in all_cats:
        known_vectors = deserialize_data(vectors_blob)
        similarities = [1 - cosine(query_vector, vec) for vec in known_vectors]
        max_sim_for_this_cat = np.max(similarities)
        if max_sim_for_this_cat > highest_similarity:
            highest_similarity = max_sim_for_this_cat
            best_match_name = name
    return best_match_name, highest_similarity, None


# --- 3. FlaskæœåŠ¡å™¨ä¸å·¥ä½œçº¿ç¨‹ ---

app = Flask(__name__)
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# è¯†åˆ«é˜Ÿåˆ—å’Œç»“æœå­—å…¸
recognition_queue = queue.Queue()
recognition_results = {}

# å…¨å±€åŠ è½½AIæ¨¡å‹
YOLO_MODEL, FEATURE_EXTRACTOR = load_ai_models()
if not YOLO_MODEL:
    print("å…³é”®AIæ¨¡å‹åŠ è½½å¤±è´¥ï¼ŒæœåŠ¡å™¨æ— æ³•å¯åŠ¨ã€‚")
    sys.exit(1)


def ai_recognition_worker():
    """
    å…¨è‡ªåŠ¨AIè¯†åˆ«å·¥ä½œçº¿ç¨‹ã€‚
    å®ƒä¼šä»é˜Ÿåˆ—ä¸­è·å–ä»»åŠ¡ï¼Œè°ƒç”¨AIæ¨¡å‹è¿›è¡Œè¯†åˆ«ï¼Œå¹¶å°†ç»“æœå­˜å…¥å­—å…¸ã€‚
    """
    print("âœ… AIè¯†åˆ«å·¥ä½œçº¿ç¨‹å·²å¯åŠ¨ï¼Œç­‰å¾…å¤„ç†ä»»åŠ¡...")
    while True:
        try:
            task_id, image_path, filename = recognition_queue.get()
            if task_id is None: break  # é€€å‡ºä¿¡å·

            logger.info(f"å¼€å§‹å¤„ç†ä»»åŠ¡ {task_id} ({filename})...")

            # 1. æå–æŸ¥è¯¢å‘é‡
            query_vector = extract_feature_from_image(image_path, YOLO_MODEL, FEATURE_EXTRACTOR)

            if query_vector is None:
                logger.warning(f"ä»»åŠ¡ {task_id}: æœªèƒ½åœ¨å›¾ç‰‡ {filename} ä¸­æ£€æµ‹åˆ°çŒ«è„¸ã€‚")
                recognition_results[task_id] = {'error': 'face_not_detected'}
                continue

            # 2. åœ¨æ•°æ®åº“ä¸­åŒ¹é…
            cat_name, similarity, db_error = find_most_similar_cat(query_vector, DATABASE_FILE)

            if db_error:
                logger.error(f"ä»»åŠ¡ {task_id}: {db_error}")
                recognition_results[task_id] = {'error': db_error}
                continue

            # 3. æ ¹æ®ç½®ä¿¡åº¦ç»™å‡ºä¸åŒçš„æç¤ºè¯
            # è¿™æ˜¯æˆ‘ä»¬å®ç°æ–°éœ€æ±‚çš„æ ¸å¿ƒé€»è¾‘
            if similarity >= SIMILARITY_THRESHOLD:
                status = "matched"
                message = f"è¯†åˆ«æˆåŠŸï¼è¿™å¾ˆå¯èƒ½æ˜¯ {cat_name}ã€‚"
                if similarity > 0.85:
                    message += " (ç½®ä¿¡åº¦: éå¸¸é«˜)"
                elif similarity > 0.75:
                    message += " (ç½®ä¿¡åº¦: è¾ƒé«˜)"
                else:
                    message += " (ç½®ä¿¡åº¦: å¯ä¿¡)"
                result_name = cat_name
            else:
                status = "unmatched"
                message = f"æœªåœ¨æ•°æ®åº“ä¸­æ‰¾åˆ°è¶³å¤Ÿç›¸ä¼¼çš„çŒ«ã€‚æœ€æ¥è¿‘çš„æ˜¯ {cat_name} (ç›¸ä¼¼åº¦ {similarity:.2f})ï¼Œä½†æœªè¾¾åˆ°é˜ˆå€¼ {SIMILARITY_THRESHOLD}ã€‚"
                result_name = "å¾…å®š (Unknown)"  # ä½äºé˜ˆå€¼ï¼Œæ˜¾ç¤ºä¸ºå¾…å®š

            # 4. å°†åŒ…å«ä¸°å¯Œä¿¡æ¯çš„ç»“æœå­˜å…¥å­—å…¸
            recognition_results[task_id] = {
                'status': status,
                'cat_name': result_name,
                'similarity': float(f"{similarity:.4f}"),
                'message': message,
                'matched_cat': cat_name if similarity >= SIMILARITY_THRESHOLD else None
            }

        except Exception as e:
            logger.error(f"AIå·¥ä½œçº¿ç¨‹å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)
            # ç¡®ä¿å³ä½¿å‡ºé”™ä¹Ÿèƒ½ç»™å‰ç«¯ä¸€ä¸ªå“åº”
            if 'task_id' in locals() and task_id not in recognition_results:
                recognition_results[task_id] = {'error': 'worker_exception'}
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'image_path' in locals() and os.path.exists(image_path):
                try:
                    os.remove(image_path)
                except OSError as e:
                    logger.error(f"æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {image_path}: {e}")
            if 'task_id' in locals():
                recognition_queue.task_done()


def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


@app.route('/recognize', methods=['POST'])
def recognize_api():
    """è¯†åˆ«çŒ«å’ªçš„APIç«¯ç‚¹"""
    try:
        if 'image' not in request.files:
            return jsonify({'success': False, 'error': 'No image file provided'}), 400
        file = request.files['image']
        if file.filename == '' or not allowed_file(file.filename):
            return jsonify({'success': False, 'error': 'Invalid file format or no file selected'}), 400

        filename = secure_filename(file.filename)
        temp_path = os.path.join(UPLOAD_FOLDER, f"{uuid.uuid4()}{os.path.splitext(filename)[1].lower()}")
        file.save(temp_path)
        logger.info(f"æ”¶åˆ°è¯†åˆ«è¯·æ±‚: {filename}ï¼Œå·²ä¿å­˜è‡³ {temp_path}")

        task_id = str(uuid.uuid4())
        recognition_queue.put((task_id, temp_path, filename))

        # ç­‰å¾…è¯†åˆ«ç»“æœï¼ˆæœ€å¤š30ç§’ï¼‰
        timeout_seconds = 30
        for _ in range(timeout_seconds * 10):
            if task_id in recognition_results:
                result = recognition_results.pop(task_id)

                # æ£€æŸ¥workeræ˜¯å¦å‡ºé”™
                if result.get('error'):
                    error_msg = result['error']
                    logger.error(f"è¯†åˆ«å¤±è´¥: {error_msg}")
                    return jsonify({'success': False, 'error': error_msg}), 500

                logger.info(f"è¿”å›è¯†åˆ«ç»“æœ: {result}")
                return jsonify({'success': True, 'data': result})

            time.sleep(0.1)

        logger.error("è¯†åˆ«è¶…æ—¶")
        return jsonify({'success': False, 'error': 'timeout'}), 408

    except Exception as e:
        logger.error(f"API /recognize å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
        return jsonify({'success': False, 'error': 'server_error'}), 500


# --- å…¶ä»–è¾…åŠ©APIç«¯ç‚¹ (å¥åº·æ£€æŸ¥ç­‰) ---
@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({'status': 'healthy', 'service': 'AI Cat Recognition Server'})


@app.route('/status', methods=['GET'])
def status():
    return jsonify({'queue_size': recognition_queue.qsize(), 'threshold': SIMILARITY_THRESHOLD})


if __name__ == '__main__':
    print("=" * 60)
    print("ğŸš€ å¯åŠ¨å…¨è‡ªåŠ¨AIçŒ«å’ªè¯†åˆ«æœåŠ¡å™¨...")
    print(f"   æœåŠ¡å™¨åœ°å€: http://localhost:{SERVER_PORT}")
    print(f"   APIç«¯ç‚¹: POST /recognize")
    print(f"   è¯†åˆ«é˜ˆå€¼ (Threshold): {SIMILARITY_THRESHOLD}")
    print("=" * 60)

    # å¯åŠ¨AIè¯†åˆ«å·¥ä½œçº¿ç¨‹
    recognition_thread = threading.Thread(target=ai_recognition_worker, daemon=True)
    recognition_thread.start()

    try:
        # æ¨èåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ waitress æˆ– gunicorn ä»£æ›¿ app.run
        app.run(host='0.0.0.0', port=SERVER_PORT)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å™¨æ­£åœ¨å…³é—­...")
        recognition_queue.put((None, None, None))  # å‘é€é€€å‡ºä¿¡å·
        sys.exit(0)